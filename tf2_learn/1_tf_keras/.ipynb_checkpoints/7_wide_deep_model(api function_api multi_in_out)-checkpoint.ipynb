{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7  Wide & Deep模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.1 模型解读**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.1.1 稀疏特征和密集特征**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 谷歌于2016年发布的模型，原适用于推荐系统\n",
    "- 可以适用于分类和回归\n",
    "- 利用数据的稀疏特征和密集特征构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**稀疏特征**\n",
    "- 离散值特征\n",
    "- wd模型中使用one-hot表示\n",
    "- 稀疏特征之间便于进行组合，即特征交互\n",
    "    - 便于产生新的描述特征\n",
    "    - 便于处理共现特征\n",
    "- 优点\n",
    "    - 有效，大量用于工业界(CTR)\n",
    "    - 便于进行需要特征分裂的算法，如树算法\n",
    "- 缺点\n",
    "    - 人工设计\n",
    "    - 耗费存储\n",
    "    \n",
    "    \n",
    "\n",
    "**密集特征**\n",
    "- 向量表达\n",
    "    -词表->向量：Word2Vec\n",
    "- 优点\n",
    "    - 带有语义和关联信息\n",
    "    - 可以兼容新的特征组合\n",
    "    - 较少人工参与\n",
    "- 缺点\n",
    "    - 过度泛化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **7.1.2 模型结构**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='align-items:center'>\n",
    "<img src='../image/1_1_wide_deep.png', alt='wide_deep_model'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**wide & deep**模型将wide模型和deep模型组合起来，其中\n",
    "- wide模型只有一层，所有的稀疏输入会连接到输出层上\n",
    "- deep模型通过将稀疏特征的密集化表示，然后将密集特征输入到深层的神经网络中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例结构**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='align-items:center'>\n",
    "<img src='../image/1_2_wide_deep.png', alt='wide_deep_model'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图将*user installed app*和*impression app*进行特征组合后输入到了wide模型中，而其他的输入部分进行了密集嵌入，部分没有"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.2 代码实现（回归为例）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.2.1 数据导入**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os, sys, time, gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_all, X_test, y_train_all, y_test = train_test_split(housing.data, housing.target, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "X_train_scaled = std_scaler.fit_transform(X_train)\n",
    "X_val_scaled = std_scaler.transform(X_val)\n",
    "X_test_scaled = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.2.2 模型构建(函数式API)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数式API构建\n",
    "#deep_model\n",
    "input = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "\n",
    "# 拼接\n",
    "concat = keras.layers.concatenate([input, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = keras.models.Model(inputs=[input], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 113us/sample - loss: 3.9651 - val_loss: 1.5798\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 1.0974 - val_loss: 0.7428\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.6976 - val_loss: 0.5489\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5371 - val_loss: 0.4769\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4738 - val_loss: 0.4405\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4433 - val_loss: 0.4233\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4269 - val_loss: 0.4085\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4150 - val_loss: 0.4007\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.4068 - val_loss: 0.3903\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3977 - val_loss: 0.3846\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3915 - val_loss: 0.3791\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3880 - val_loss: 0.3801\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3820 - val_loss: 0.3679\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3775 - val_loss: 0.3671\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3744 - val_loss: 0.3594\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3646 - val_loss: 0.3560\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3607 - val_loss: 0.3541\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3575 - val_loss: 0.3510\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3536 - val_loss: 0.3546\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3519 - val_loss: 0.3430\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(min_delta=1e-3, patience=3),]\n",
    "history = model.fit(X_train_scaled, y_train, batch_size=128, epochs=20, validation_data=(X_val_scaled, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.2.3 模型构建（子类api）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 继承Model来创建一个Model\n",
    "\n",
    "class WideDeepModel(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(WideDeepModel, self).__init__()\n",
    "        self.hidden1_layer = keras.layers.Dense(30, activation='relu')\n",
    "        self.hidden2_layer = keras.layers.Dense(30, activation='relu')\n",
    "        self.output_layer = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, input):\n",
    "        \"\"\"完成模型的前向计算\"\"\"\n",
    "        hidden1 = self.hidden1_layer(input)\n",
    "        hidden2 = self.hidden2_layer(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_layer(concat)\n",
    "        return output\n",
    "model = WideDeepModel()\n",
    "# 需要运行build来构建模型\n",
    "model.build(input_shape=(None, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wide_deep_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  930       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  39        \n",
      "=================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 74us/sample - loss: 3.1066 - val_loss: 0.9771\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.9783 - val_loss: 0.7297\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.7545 - val_loss: 0.6040\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.6095 - val_loss: 0.5164\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.5224 - val_loss: 0.4676\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4718 - val_loss: 0.4331\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.4381 - val_loss: 0.4194\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4184 - val_loss: 0.3971\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4037 - val_loss: 0.3875\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3926 - val_loss: 0.3811\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3854 - val_loss: 0.3719\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3781 - val_loss: 0.3763\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3753 - val_loss: 0.3680\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3676 - val_loss: 0.3578\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3622 - val_loss: 0.3545\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3588 - val_loss: 0.3501\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3551 - val_loss: 0.3503\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3542 - val_loss: 0.3460\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3475 - val_loss: 0.3457\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3493 - val_loss: 0.3401\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# 也可以放到Sequential模型中\n",
    "model.compile(loss='mse', optimizer='Adam')\n",
    "callbacks = [keras.callbacks.EarlyStopping(min_delta=1e-3, patience=3),]\n",
    "history = model.fit(X_train_scaled, y_train, batch_size=128, epochs=20, validation_data=(X_val_scaled, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model; gc.collect();\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.2.4 模型构建（多输入）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = keras.layers.Input(shape=[5])\n",
    "input_deep = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_deep)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_wide, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_wide, input_deep], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_wide = X_train_scaled[:, :5]\n",
    "X_train_scaled_deep = X_train_scaled[:, 2:]\n",
    "X_val_scaled_wide = X_val_scaled[:, :5]\n",
    "X_val_scaled_deep = X_val_scaled[:, 2:]\n",
    "model.compile(loss='mse', optimizer='Adam')\n",
    "callbacks = [keras.callbacks.EarlyStopping(min_delta=1e-3, patience=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 89us/sample - loss: 3.5630 - val_loss: 1.7487\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 1.4440 - val_loss: 0.9846\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.9233 - val_loss: 0.7400\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.7164 - val_loss: 0.6115\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.6108 - val_loss: 0.5423\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.5530 - val_loss: 0.5025\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5164 - val_loss: 0.4685\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4870 - val_loss: 0.4441\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4596 - val_loss: 0.4241\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4405 - val_loss: 0.4082\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_scaled_wide, X_train_scaled_deep), y_train,\n",
    "                    validation_data=[[X_val_scaled_wide, X_val_scaled_deep], y_val], epochs=10, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model; gc.collect();\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.2.5 模型构建（多输入多输出）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多输出模型通常应用在多任务学习的模型中，wide&deep模型本身不是一个多输出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = keras.layers.Input(shape=[5])\n",
    "input_deep = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_deep)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_wide, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "output2 = keras.layers.Dense(1)(hidden2)\n",
    "model = keras.models.Model(inputs=[input_wide, input_deep], outputs=[output, output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='Adam')\n",
    "callbacks = [keras.callbacks.EarlyStopping(min_delta=1e-3, patience=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 88us/sample - loss: 7.0961 - dense_6_loss: 3.4516 - dense_7_loss: 3.6313 - val_loss: 3.3459 - val_dense_6_loss: 1.5104 - val_dense_7_loss: 1.8068\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 2.9662 - dense_6_loss: 1.3189 - dense_7_loss: 1.6441 - val_loss: 2.1398 - val_dense_6_loss: 0.9412 - val_dense_7_loss: 1.1857\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 2.0264 - dense_6_loss: 0.8920 - dense_7_loss: 1.1348 - val_loss: 1.5946 - val_dense_6_loss: 0.7203 - val_dense_7_loss: 0.8676\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 1.5525 - dense_6_loss: 0.7102 - dense_7_loss: 0.8415 - val_loss: 1.3498 - val_dense_6_loss: 0.6212 - val_dense_7_loss: 0.7251\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 1.3676 - dense_6_loss: 0.6287 - dense_7_loss: 0.7391 - val_loss: 1.2345 - val_dense_6_loss: 0.5633 - val_dense_7_loss: 0.6704\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 1.2835 - dense_6_loss: 0.5799 - dense_7_loss: 0.7028 - val_loss: 1.1565 - val_dense_6_loss: 0.5212 - val_dense_7_loss: 0.6351\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 1.1972 - dense_6_loss: 0.5379 - dense_7_loss: 0.6588 - val_loss: 1.0889 - val_dense_6_loss: 0.4901 - val_dense_7_loss: 0.6005\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 1.1333 - dense_6_loss: 0.5074 - dense_7_loss: 0.6275 - val_loss: 1.0441 - val_dense_6_loss: 0.4696 - val_dense_7_loss: 0.5767\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 1.0792 - dense_6_loss: 0.4797 - dense_7_loss: 0.5989 - val_loss: 0.9946 - val_dense_6_loss: 0.4452 - val_dense_7_loss: 0.5519\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 1.0359 - dense_6_loss: 0.4596 - dense_7_loss: 0.5764 - val_loss: 0.9579 - val_dense_6_loss: 0.4290 - val_dense_7_loss: 0.5317\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_scaled_wide, X_train_scaled_deep), [y_train, y_train],\n",
    "                    validation_data=[[X_val_scaled_wide, X_val_scaled_deep], [y_val, y_val]],\n",
    "                                     epochs=10, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model; gc.collect();\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_tr12",
   "language": "python",
   "name": "tf2_tr12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
