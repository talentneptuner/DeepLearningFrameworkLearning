{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import os, gc, sys, time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn')\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.1数据集titanic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = './data/titanic/titanic_train.csv'\n",
    "eval_file = './data/titanic/titanic_eval.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>Second</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>Third</td>\n",
       "      <td>G</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500   Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833   First        C   \n",
       "2  female  26.0                   0      0   7.9250   Third  unknown   \n",
       "3  female  35.0                   1      0  53.1000   First        C   \n",
       "4    male  28.0                   0      0   8.4583   Third  unknown   \n",
       "5    male   2.0                   3      1  21.0750   Third  unknown   \n",
       "6  female  27.0                   0      2  11.1333   Third  unknown   \n",
       "7  female  14.0                   1      0  30.0708  Second  unknown   \n",
       "8  female   4.0                   1      1  16.7000   Third        G   \n",
       "9    male  20.0                   0      0   8.0500   Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  \n",
       "5  Southampton     n  \n",
       "6  Southampton     n  \n",
       "7    Cherbourg     n  \n",
       "8  Southampton     n  \n",
       "9  Southampton     y  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23090f23668>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.age.hist(bins = 20) # 年龄分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x230930927b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD3CAYAAAAQYlNPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAALNklEQVR4nO3ca4ycdRmG8WthOZoVEAaViJBIfaJCUFDBSKAWkChpIJiIIXI2RCQoWkVUCGo00URQ0HCQUBBBMXKwIYitishJJWAxKPggYDwCrgilAhEL44d5V9dmt+1ut/u+y3P9vnRnpjtz999tr52ZwlC/30eSVNdGbQ+QJLXLEEhScYZAkoozBJJUnCGQpOKG2x4wVatWPdd//PGn254xoW222RK3TZ3bpsdt09PVbRt6V683MjTZbXPuGcHw8MZtT5iU26bHbdPjtunp6rY2d825EEiSZpYhkKTiDIEkFWcIJKk4QyBJxRkCSSrOEEhScYZAkoozBJJUnCGQpOIMgSQVZwgkqThDIEnFGQJJKs4QSFJxhkCSijMEklScIZCk4gyBJBVnCCSpOEMgScUZAkkqzhBIUnGGQJKKMwSSVJwhkKTihtseMFULFy1pe4K0RotPW9D2BGlKfEYgScUZAkkqzhBIUnGGQJKKMwSSVJwhkKTiDIEkFWcIJKk4QyBJxRkCSSrOEEhScYZAkoozBJJUnCGQpOIMgSQVZwgkqThDIEnFGQJJKs4QSFJxhkCSijMEklScIZCk4gyBJBU3vKYbI2Jj4PvAi4CFmfn4TDxoRDySmS+bifuSJK2fNYYAeDmwXWbuORtjJEmzb20h+DowLyIuAUaAbZvrP5iZ90TEA8DtwDzgRmAr4M1AZuaREbErcDaDl6C2bj7v9rE7j4jdgHOBIeAx4LjMXDFjvzpJ0lqtLQQfAK4E/gbckZnnR8Q84BJgH2BnYAHwMPAPYC/gZOChiNgaeB2wqInGEcCxDMIx5iIGf/nfGxHHA6cCn5qpX5zUhl5v5AX5WFPltqlra9faQjBmN2BBRBzeXN6m+fGxzPwjQEQ8lZn3Nh+vADYH/gKcERHPMHhG8eRq9/sa4LyIANgEuH+6vxCpK0ZHV87K4/R6I7P2WFPltqnb0LvWFJl1/VdDvwW+nJnzgXcDVzTX99fyeecCZ2bm0cA9DF4CGi+Bo5r7PRW4fh33SJJmyLo+I/g8cHFEnAC8GPj0On7e5cCSiHgU+DOw3Wq3nwhc1vzrJIDj1/F+JUkzZKjfX9s39d2ycNGSuTVY5Sw+bcGsPE5XX+IAt03HLLw0tPorMv/lf1AmScUZAkkqzhBIUnGGQJKKMwSSVJwhkKTiDIEkFWcIJKk4QyBJxRkCSSrOEEhScYZAkoozBJJUnCGQpOIMgSQVZwgkqThDIEnFGQJJKs4QSFJxhkCSijMEklScIZCk4obbHjBV1511CKOjK9ueMaFeb8Rt0+A2qV0+I5Ck4gyBJBVnCCSpOEMgScUZAkkqzhBIUnGGQJKKMwSSVJwhkKTiDIEkFWcIJKk4QyBJxRkCSSrOEEhScYZAkoozBJJUnCGQpOIMgSQVZwgkqThDIEnFGQJJKs4QSFJxhkCSijMEklScIZCk4gyBJBVnCCSpOEMgScUZAkkqzhBIUnGGQJKKMwSSVJwhkKTiDIEkFWcIJKk4QyBJxRkCSSrOEEhScYZAkoozBJJUnCGQpOIMgSQVZwgkqThDIEnFGQJJKs4QSFJxhkCSijMEklScIZCk4gyBJBVnCCSpOEMgScUZAkkqbrjtAVO1cNGStidI0qxbfNqCDXbfPiOQpOIMgSQVZwgkqThDIEnFGQJJKs4QSFJxhkCSijMEklScIZCk4gyBJBVnCCSpOEMgScUZAkkqzhBIUnGGQJKKMwSSVJwhkKTiDIEkFWcIJKk4QyBJxRkCSSrOEEhScYZAkoozBJJUXCshiIhjIuILbTy2JOn/+YxAkoobXt87iIhjgIXAFsDLgXOAQ4BdgY8COwKHAZsAK5qPx3/+ycARQB+4MjPPXd9NkvRC0+uNbLD7Xu8QNEYy8+0R8R7gw8DewPzm47uAAzLz+YhYCrxp7JMi4rXA4cA+DELwo4hYmpk5Q7sk6QVhdHTlen3+mkIyUy8NLW9+fAK4LzP7wOPApsCzwLcj4mLgFQyeGYzZFdgJ+DFwI7AtsMsMbZIkrYOZCkF/kus3BQ7NzMOBk5vHGxp3ewK/Ad6WmfOBS4F7ZmiTJGkdbOg3i1cBT0XEncAPgYeBHcZuzMxfMXg2cGvzc+YBf9nAmyRJ4wz1+5N9M99NCxctmVuDJWkGLD5twXp9fq83MjTZbf7zUUkqzhBIUnGGQJKKMwSSVJwhkKTiDIEkFWcIJKk4QyBJxRkCSSrOEEhScYZAkoozBJJUnCGQpOIMgSQVZwgkqThDIEnFGQJJKs4QSFJxhkCSijMEklScIZCk4gyBJBU31O/3294wVf3R0ZVtb5hQrzeC26bObdPjtunp6rYNvavXGxma7DafEUhScYZAkoozBJJUnCGQpOIMgSQVZwgkqThDIEnFGQJJKs4QSFJxhkCSijMEklScIZCk4gyBJBVnCCSpOEMgScUZAkkqzhBIUnGGQJKKMwSSVJwhkKTiDIEkFWcIJKk4QyBJxRkCSSrOEEhScYZAkoob6vf7bW+QJLXIZwSSVJwhkKTiDIEkFWcIJKk4QyBJxRkCSSrOEEhSccNtD1hXEbERcB6wO/Av4H2Z+UDLm5YDK5qLvwcuBM4BVgHLMvMzLWzaC/hiZs6PiF2AS4E+8GvgpMx8PiLOBA5udp6SmXe0sG0P4Drgd83N52fmd2Z7W0RsAiwGdgY2Az4H3EsHzm2SbX+mG+e2MXAREMBzwLHAEN04t4m2bUUHzq3Ztz1wF3Bg87iX0vKZzZkQAIcCm2fmWyJib+As4JC2xkTE5gCZOX/cdXcD7wIeAq6PiD0y85ezuOlU4Ejgqeaqs4HTM/OmiLgAOCQi/gDsB+wF7AhcDbyphW17AGdn5lnjfs4eLWx7L/BYZh4ZEdsCy4G76ca5TbTts3Tj3BYCZOZbI2I+g6+1IbpxbhNtu44OnFsT9wuBZ5qrOvFndC69NLQP8AOAzPw58MZ257A7sGVELIuIGyNiX2CzzHwwM/vAUmD/Wd70IHDYuMt7Aj9tPr4BOIDBOS7LzH5m/hEYjoheS9sOjoibI+LiiBhpadt3gTPGXV5Fd85tsm2tn1tmfg84obm4E/AoHTm3NWxr/dyALwEXAH9tLnfizOZSCF7M/16GAXguItp8RvM0g9/Ug4D3A5c0141ZyeDp6KzJzKuBf4+7aqiJ0vg9q5/jrOycYNsdwMcyc18Gz6DObGNbZv4zM1c2fzFcBZxOR85tkm2dOLdm36qI+Abw1WZfJ85tkm2tn1tEHAOMZubScVd34szmUgieBEbGXd4oM1e1NQa4H7i8qfb9DH7jXjLu9hHgiVaW/c/z4z4e27P6Oba189rMvGvsY+ANtLQtInYEfgJ8MzO/RYfObYJtnTk3gMw8Gng1g9fkt5hgQ1e2LevAuR0HHBgRNwGvBy4Dtp/g8Wf9zOZSCG4D3gnQvEdwT7tzOI7B+xRExA7AlsBTEfGqiBhi8Ezhlhb3ASxvXiMFeAeDPbcBB0XERhHxSgZB/XsL25ZGxJubj/dn8ObZrG+LiJcCy4CPZ+bi5upOnNsk27pybkdGxCeai08ziOedHTm3ibZd0/a5Zea+mblf877i3cBRwA1dOLO59GbxtQxqejuDN6WObXnPxcClEXErg3f8j2PwBXcFsDGD70B+0eI+gEXARRGxKXAfcFVmPhcRtwA/Y/CNwEktbTsR+FpEPAs8ApyQmU+2sO2TwDbAGREx9nr8h4BzO3BuE237CPCVDpzbNcAlEXEzsAlwCoOz6sLX20Tb/kQ3vt5W14k/o/5vqCWpuLn00pAkaQMwBJJUnCGQpOIMgSQVZwgkqThDIEnFGQJJKu4/pSXTJ2IBAZ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.sex.value_counts().plot(kind='barh') # 性别分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2309310aac8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['class'].value_counts().plot(kind='barh') # class与自带函数冲突, 舱位分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23093178358>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([train_df, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh') # 男女获救比例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2 feature_column的使用**\n",
    "**离散特征**: one-hot编码     \n",
    "**连续特征**: 分桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                       'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "# 将类别特征转换为one-hot的特征\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    # 使用tf.feature_columns下的api\n",
    "    feature_columns.append(tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(categorical_column, vocab)))\n",
    "for categorical_column in numeric_columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(categorical_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True, batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_df, y_train, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: id=38, shape=(5,), dtype=string, numpy=array([b'male', b'female', b'female', b'female', b'male'], dtype=object)>, 'age': <tf.Tensor: id=30, shape=(5,), dtype=float64, numpy=array([22., 38., 26., 35., 28.])>, 'n_siblings_spouses': <tf.Tensor: id=36, shape=(5,), dtype=int32, numpy=array([1, 1, 0, 1, 0])>, 'parch': <tf.Tensor: id=37, shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 0])>, 'fare': <tf.Tensor: id=35, shape=(5,), dtype=float64, numpy=array([ 7.25  , 71.2833,  7.925 , 53.1   ,  8.4583])>, 'class': <tf.Tensor: id=32, shape=(5,), dtype=string, numpy=array([b'Third', b'First', b'Third', b'First', b'Third'], dtype=object)>, 'deck': <tf.Tensor: id=33, shape=(5,), dtype=string, numpy=array([b'unknown', b'C', b'unknown', b'C', b'unknown'], dtype=object)>, 'embark_town': <tf.Tensor: id=34, shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Cherbourg', b'Southampton', b'Southampton',\n",
      "       b'Queenstown'], dtype=object)>, 'alone': <tf.Tensor: id=31, shape=(5,), dtype=string, numpy=array([b'n', b'n', b'y', b'n', b'y'], dtype=object)>} tf.Tensor([0 1 1 1 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3 使用DenseFeature来使用feature_column**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_columns定义的是特征转换的规则，keras.layers.DenseFeature将规则运用在dataset上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[22.]\n",
      " [38.]\n",
      " [26.]\n",
      " [35.]\n",
      " [28.]]\n",
      "WARNING:tensorflow:Layer dense_features_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    age_column = feature_columns[7]\n",
    "    gender_column = feature_columns[0]\n",
    "    print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
    "    print(keras.layers.DenseFeatures(gender_column)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[22.      1.      0.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "   7.25    1.      0.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [38.      1.      0.      0.      1.      0.      0.      1.      0.\n",
      "   0.      0.      0.      0.      0.      0.      1.      0.      0.\n",
      "  71.2833  1.      0.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      0.      1.    ]\n",
      " [26.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "   7.925   0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      0.      1.    ]\n",
      " [35.      1.      0.      0.      1.      0.      0.      1.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  53.1     1.      0.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      0.      1.    ]\n",
      " [28.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      0.      1.      0.\n",
      "   8.4583  0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.4 利用DenseFeature来构建模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer = keras.optimizers.Adam(lr=0.01),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有两种训练的模式\n",
    "- 直接调用fit的方法\n",
    "- 将model转换为estimator，然后再进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 19 steps, validate for 8 steps\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3630 - accuracy: 0.8388 - val_loss: 0.5187 - val_accuracy: 0.7773\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3583 - accuracy: 0.8536 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3486 - accuracy: 0.8487 - val_loss: 0.5076 - val_accuracy: 0.7930\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3328 - accuracy: 0.8553 - val_loss: 0.5139 - val_accuracy: 0.7891\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3371 - accuracy: 0.8520 - val_loss: 0.5153 - val_accuracy: 0.8086\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3437 - accuracy: 0.8454 - val_loss: 0.5105 - val_accuracy: 0.8086\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3380 - accuracy: 0.8536 - val_loss: 0.5218 - val_accuracy: 0.8047\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3279 - accuracy: 0.8553 - val_loss: 0.5228 - val_accuracy: 0.8125\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3521 - accuracy: 0.8602 - val_loss: 0.5221 - val_accuracy: 0.8164\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3342 - accuracy: 0.8553 - val_loss: 0.5158 - val_accuracy: 0.8008\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3389 - accuracy: 0.8602 - val_loss: 0.5159 - val_accuracy: 0.8164\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3273 - accuracy: 0.8536 - val_loss: 0.5311 - val_accuracy: 0.8047\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3382 - accuracy: 0.8586 - val_loss: 0.5187 - val_accuracy: 0.8438\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3350 - accuracy: 0.8553 - val_loss: 0.5193 - val_accuracy: 0.8242\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3448 - accuracy: 0.8487 - val_loss: 0.5170 - val_accuracy: 0.8398\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3314 - accuracy: 0.8569 - val_loss: 0.5250 - val_accuracy: 0.8320\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3327 - accuracy: 0.8569 - val_loss: 0.5185 - val_accuracy: 0.8477\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3402 - accuracy: 0.8536 - val_loss: 0.5235 - val_accuracy: 0.8398\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3352 - accuracy: 0.8553 - val_loss: 0.5384 - val_accuracy: 0.8359\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3623 - accuracy: 0.8388 - val_loss: 0.5419 - val_accuracy: 0.8359\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3820 - accuracy: 0.8536 - val_loss: 0.5391 - val_accuracy: 0.8281\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3449 - accuracy: 0.8503 - val_loss: 0.5231 - val_accuracy: 0.8281\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3238 - accuracy: 0.8536 - val_loss: 0.5134 - val_accuracy: 0.8242\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3373 - accuracy: 0.8569 - val_loss: 0.5206 - val_accuracy: 0.8047\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3325 - accuracy: 0.8602 - val_loss: 0.5376 - val_accuracy: 0.8047\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3238 - accuracy: 0.8618 - val_loss: 0.5250 - val_accuracy: 0.8203\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3371 - accuracy: 0.8553 - val_loss: 0.5397 - val_accuracy: 0.8047\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3276 - accuracy: 0.8602 - val_loss: 0.5447 - val_accuracy: 0.7930\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3195 - accuracy: 0.8651 - val_loss: 0.5412 - val_accuracy: 0.7930\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3169 - accuracy: 0.8684 - val_loss: 0.5421 - val_accuracy: 0.7891\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3302 - accuracy: 0.8635 - val_loss: 0.5724 - val_accuracy: 0.7930\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3347 - accuracy: 0.8651 - val_loss: 0.5761 - val_accuracy: 0.7695\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3449 - accuracy: 0.8651 - val_loss: 0.5529 - val_accuracy: 0.7930\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3368 - accuracy: 0.8569 - val_loss: 0.5315 - val_accuracy: 0.7930\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3126 - accuracy: 0.8684 - val_loss: 0.5397 - val_accuracy: 0.7891\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3096 - accuracy: 0.8651 - val_loss: 0.5396 - val_accuracy: 0.7969\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3180 - accuracy: 0.8701 - val_loss: 0.5629 - val_accuracy: 0.7734\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3553 - accuracy: 0.8586 - val_loss: 0.5527 - val_accuracy: 0.7773\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3369 - accuracy: 0.8553 - val_loss: 0.5483 - val_accuracy: 0.7734\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3248 - accuracy: 0.8586 - val_loss: 0.5248 - val_accuracy: 0.8086\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3111 - accuracy: 0.8701 - val_loss: 0.5288 - val_accuracy: 0.7852\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3107 - accuracy: 0.8651 - val_loss: 0.5309 - val_accuracy: 0.7969\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3372 - accuracy: 0.8586 - val_loss: 0.5477 - val_accuracy: 0.7812\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3432 - accuracy: 0.8569 - val_loss: 0.5392 - val_accuracy: 0.8008\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3119 - accuracy: 0.8684 - val_loss: 0.5378 - val_accuracy: 0.8125\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3174 - accuracy: 0.8602 - val_loss: 0.5492 - val_accuracy: 0.8008\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3223 - accuracy: 0.8684 - val_loss: 0.5492 - val_accuracy: 0.8242\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3532 - accuracy: 0.8405 - val_loss: 0.5768 - val_accuracy: 0.8008\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3374 - accuracy: 0.8668 - val_loss: 0.5659 - val_accuracy: 0.8242\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3726 - accuracy: 0.8438 - val_loss: 0.5512 - val_accuracy: 0.8203\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3544 - accuracy: 0.8553 - val_loss: 0.5463 - val_accuracy: 0.8281\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3429 - accuracy: 0.8553 - val_loss: 0.5327 - val_accuracy: 0.8008\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3208 - accuracy: 0.8602 - val_loss: 0.5261 - val_accuracy: 0.8125\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3142 - accuracy: 0.8553 - val_loss: 0.5255 - val_accuracy: 0.7969\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3242 - accuracy: 0.8717 - val_loss: 0.5364 - val_accuracy: 0.8164\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3078 - accuracy: 0.8618 - val_loss: 0.5393 - val_accuracy: 0.8047\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3122 - accuracy: 0.8668 - val_loss: 0.5344 - val_accuracy: 0.8008\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 10ms/step - loss: 0.2996 - accuracy: 0.8766 - val_loss: 0.5418 - val_accuracy: 0.7969\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3167 - accuracy: 0.8766 - val_loss: 0.5507 - val_accuracy: 0.8008\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3234 - accuracy: 0.8668 - val_loss: 0.5753 - val_accuracy: 0.7891\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3145 - accuracy: 0.8668 - val_loss: 0.5551 - val_accuracy: 0.7891\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3059 - accuracy: 0.8766 - val_loss: 0.5495 - val_accuracy: 0.7930\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3031 - accuracy: 0.8766 - val_loss: 0.5735 - val_accuracy: 0.7891\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3166 - accuracy: 0.8668 - val_loss: 0.5959 - val_accuracy: 0.7891\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3273 - accuracy: 0.8684 - val_loss: 0.5487 - val_accuracy: 0.8047\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3071 - accuracy: 0.8684 - val_loss: 0.5881 - val_accuracy: 0.7969\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3321 - accuracy: 0.8586 - val_loss: 0.5501 - val_accuracy: 0.7969\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3068 - accuracy: 0.8701 - val_loss: 0.5523 - val_accuracy: 0.8047\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.2968 - accuracy: 0.8799 - val_loss: 0.5532 - val_accuracy: 0.7930\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3018 - accuracy: 0.8783 - val_loss: 0.5533 - val_accuracy: 0.8008\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3003 - accuracy: 0.8816 - val_loss: 0.5709 - val_accuracy: 0.8047\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3157 - accuracy: 0.8602 - val_loss: 0.5632 - val_accuracy: 0.7930\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3291 - accuracy: 0.8684 - val_loss: 0.5382 - val_accuracy: 0.7969\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3279 - accuracy: 0.8684 - val_loss: 0.5669 - val_accuracy: 0.7891\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3103 - accuracy: 0.8799 - val_loss: 0.5625 - val_accuracy: 0.7891\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3220 - accuracy: 0.8635 - val_loss: 0.5659 - val_accuracy: 0.7930\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3103 - accuracy: 0.8766 - val_loss: 0.5627 - val_accuracy: 0.8008\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.2976 - accuracy: 0.8799 - val_loss: 0.5675 - val_accuracy: 0.8047\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.2985 - accuracy: 0.8684 - val_loss: 0.5851 - val_accuracy: 0.8164\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3026 - accuracy: 0.8734 - val_loss: 0.5855 - val_accuracy: 0.8047\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.3207 - accuracy: 0.8618 - val_loss: 0.5892 - val_accuracy: 0.7969\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3416 - accuracy: 0.8586 - val_loss: 0.6214 - val_accuracy: 0.8008\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3154 - accuracy: 0.8684 - val_loss: 0.5861 - val_accuracy: 0.8164\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3717 - accuracy: 0.8569 - val_loss: 0.6093 - val_accuracy: 0.8086\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3367 - accuracy: 0.8684 - val_loss: 0.5928 - val_accuracy: 0.8125\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3149 - accuracy: 0.8734 - val_loss: 0.5825 - val_accuracy: 0.7930\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3056 - accuracy: 0.8651 - val_loss: 0.5804 - val_accuracy: 0.7969\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3023 - accuracy: 0.8635 - val_loss: 0.5833 - val_accuracy: 0.7891\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.2859 - accuracy: 0.8734 - val_loss: 0.5855 - val_accuracy: 0.7812\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.2973 - accuracy: 0.8701 - val_loss: 0.5850 - val_accuracy: 0.7852\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3243 - accuracy: 0.8701 - val_loss: 0.6006 - val_accuracy: 0.7891\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3305 - accuracy: 0.8668 - val_loss: 0.6184 - val_accuracy: 0.7891\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3098 - accuracy: 0.8734 - val_loss: 0.5904 - val_accuracy: 0.7773\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.3030 - accuracy: 0.8734 - val_loss: 0.6006 - val_accuracy: 0.7852\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.2902 - accuracy: 0.8832 - val_loss: 0.5957 - val_accuracy: 0.7812\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.2871 - accuracy: 0.8816 - val_loss: 0.6060 - val_accuracy: 0.7812\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.2978 - accuracy: 0.8750 - val_loss: 0.6181 - val_accuracy: 0.7812\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.2973 - accuracy: 0.8816 - val_loss: 0.6074 - val_accuracy: 0.7773\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.2850 - accuracy: 0.8849 - val_loss: 0.6175 - val_accuracy: 0.7852\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.2941 - accuracy: 0.8783 - val_loss: 0.6162 - val_accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset(train_df, y_train, epochs=100, shuffle=True)\n",
    "eval_dataset = make_dataset(eval_df, y_eval, epochs=1, shuffle=False)\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data = eval_dataset,\n",
    "                    steps_per_epoch = 19, \n",
    "                    validation_steps = 8,\n",
    "                    epochs = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\11417\\AppData\\Local\\Temp\\tmptvns__95\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\11417\\\\AppData\\\\Local\\\\Temp\\\\tmptvns__95', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002321BDE4160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4e67249f8d1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_to_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# input_fn: 返回结果必须是a.(features, labels) b. dataset(feature, label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1158\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1188\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1190\u001b[1;33m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1191\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m(features, labels, mode)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[0;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[1;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[1;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mclone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m       \u001b[0mclone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     if all([isinstance(clone, Sequential),\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36mclone_model\u001b[1;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[0;32m    417\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     return _clone_sequential_model(\n\u001b[1;32m--> 419\u001b[1;33m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[0;32m    420\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     return _clone_functional_model(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[1;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[0;32m    336\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dp_gpu_tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    985\u001b[0m                         sparse_tensor.SparseTensor)):\n\u001b[0;32m    986\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[1;32m--> 987\u001b[1;33m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[0;32m    988\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_history'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "# input_fn: 返回结果必须是a.(features, labels) b. dataset(feature, label)\n",
    "estimator.train(input_fn = lambda : make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**这里是tf本身的问题，待到日后解决**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_tr12",
   "language": "python",
   "name": "tf2_tr12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
