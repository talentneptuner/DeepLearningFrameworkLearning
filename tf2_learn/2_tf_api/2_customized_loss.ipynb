{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os, sys, time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **加载加利福利亚数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_all, X_test, y_train_all, y_test = train_test_split(housing.data, housing.target, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "X_train_scaled = std_scaler.fit_transform(X_train)\n",
    "X_val_scaled = std_scaler.transform(X_val)\n",
    "X_test_scaled = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **模型创建**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **自定义损失函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(128, activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1, activation='relu'))\n",
    "model.summary()\n",
    "model.compile(loss=customized_mse, optimizer='Adam', metrics=['mse'])\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(min_delta=1e-3, patience=5),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 119us/sample - loss: 2.4431 - mse: 2.4431 - val_loss: 0.9245 - val_mse: 0.9245\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.8553 - mse: 0.8553 - val_loss: 0.6438 - val_mse: 0.6438\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.6302 - mse: 0.6302 - val_loss: 0.5281 - val_mse: 0.5281\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5248 - mse: 0.5248 - val_loss: 0.4688 - val_mse: 0.4688\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4687 - mse: 0.4687 - val_loss: 0.4320 - val_mse: 0.4320\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4394 - mse: 0.4394 - val_loss: 0.4092 - val_mse: 0.4092\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4205 - mse: 0.4205 - val_loss: 0.3970 - val_mse: 0.3970\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4076 - mse: 0.4076 - val_loss: 0.3877 - val_mse: 0.3877\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3984 - mse: 0.3984 - val_loss: 0.3830 - val_mse: 0.3830\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3925 - mse: 0.3925 - val_loss: 0.3705 - val_mse: 0.3705\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3873 - mse: 0.3873 - val_loss: 0.3659 - val_mse: 0.3659\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3825 - mse: 0.3825 - val_loss: 0.3635 - val_mse: 0.3635\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3782 - mse: 0.3782 - val_loss: 0.3584 - val_mse: 0.3584\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3748 - mse: 0.3748 - val_loss: 0.3588 - val_mse: 0.3588\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3718 - mse: 0.3718 - val_loss: 0.3577 - val_mse: 0.3577\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3691 - mse: 0.3691 - val_loss: 0.3530 - val_mse: 0.3530\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3666 - mse: 0.3666 - val_loss: 0.3525 - val_mse: 0.3525\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3637 - mse: 0.3637 - val_loss: 0.3480 - val_mse: 0.3480\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3615 - mse: 0.3615 - val_loss: 0.3459 - val_mse: 0.3459\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3593 - mse: 0.3593 - val_loss: 0.3442 - val_mse: 0.3442\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, batch_size=128, epochs=20, validation_data=(X_val_scaled, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learing_curve(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5)) \n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learing_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_tr12",
   "language": "python",
   "name": "tf2_tr12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
