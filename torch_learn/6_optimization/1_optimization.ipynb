{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **优化方法讲解**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用梯度下降法来寻找损失函数的最小值，但是梯度下降法对以下两个问题不能很好的解决：\n",
    "- 局部最优解\n",
    "- 鞍点 \n",
    "\n",
    "其中鞍点较局部最优解更为常见（用函数的黑塞矩阵证明）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下内容中，$\\eta_t$代表t时刻的学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **动量梯度下降**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题**:梯度下降会导致在特征取值分布不均匀的情况下，有些方向的自变量移动幅度太大。调整学习率又会使另一个方向的收敛速度变低"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**改进计算**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large v_t = \\gamma v_{t-1} + \\eta_tg_t \\\\\n",
    " \\large w_t = w_{t-1} - v_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述方法可以使得梯度下降在各个方向上的移动更加平滑，从而使得移动幅度较大的不至于太大，移动幅度较小的不至于太小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "动量梯度下降引入了**指数加权平均**的思想，使得当前梯度下降的方向不仅仅依赖于梯度，还依赖于过去方向的一致性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在pytorch中optim.sgd指定momentum参数即可使用动量梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总而言之问题在于不同参数幅度不一样导致单一学习率难以适应全部计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **AdaGrad**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**思想**:根据自变量在每个维度的梯度大小调整各个维度的学习率     \n",
    "**计算**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large s_t = s_{t-1} + g_t \\odot g_t \\\\\n",
    " \\large x_t = x_{t-1} - \\frac {\\eta}{\\sqrt{s_t + \\epsilon}} \\odot g_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出来的是当某一个维度的梯度越大的话，其学习率是越小的。     \n",
    "当早期迭代较快且解不佳时，Adagrad后期学习率太低，可能难以找到合适解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用optim.Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RMSProp**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**思想**：将Adagrad和稍作改变    \n",
    "**计算**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large s_t = \\gamma s_{t-1} + (1 - \\gamma)g_t \\odot g_t \\\\\n",
    " \\large x_t = x_{t-1} - \\frac {\\eta}{\\sqrt{s_t + \\epsilon}} \\odot g_t $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **AdaDelta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**思想**：抛弃了学习率，维护两个变量$s_t,\\Delta x_t$      \n",
    "**计算**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large s_t = \\eta s_{t-1} + (1 - \\eta)g_t \\odot g_t \\\\\n",
    " \\large {g'}_t = \\sqrt{\\frac{\\Delta x_{t-1}+\\epsilon}{s_t + \\epsilon}} \\odot g_t \\\\\n",
    " \\large x_t = x_{t-1} - {g'}_t\\\\\n",
    " \\large \\Delta x_t = \\eta \\Delta x_{t-1} + (1-\\eta){g'}_t{g'}_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Adam**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**思想**：RMSProp和动量梯度下降的结合    \n",
    "**计算**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large v_t = \\beta_1 v_{t-1} + (1-\\beta_1)g_t \\\\\n",
    "\\large s_t = \\beta_2 s_{t-1} + (1-\\beta_2)g_t \\odot g_t \\\\\n",
    "\\large \\hat v_t = \\frac{v_t}{1-\\beta_1^t} \\\\\n",
    "\\large \\hat s_t = \\frac{s_t}{1-\\beta_2^t}\\\\\n",
    "\\large {g'}_t = \\frac{\\eta \\hat v_t}{\\sqrt(\\hat s_t) + \\epsilon}\\\\\n",
    " \\large x_t = x_{t-1} - g'_t $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_tr12",
   "language": "python",
   "name": "tf2_tr12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
