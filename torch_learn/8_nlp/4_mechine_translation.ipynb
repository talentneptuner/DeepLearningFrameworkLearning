{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **机器翻译**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Seq2Seq**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq模型适用于输入和输出都不是定长序列的情况，Seq2Seq模型由编码器(encoder)和解码器(decoder)组成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里引入了两个特殊的符号“&lt;bos&gt;” 和 “&lt;eos&gt;” 。在训练数据集中，我们可以在每个句子后面附上符号 “&lt;eos&gt;”表示句子的结束，因此编码器每个时间步的输入就是\n",
    "句子的内容，标点和 “&lt;eos&gt;”标记。编码器用于提取句子编码信息并将句子信息提供给解码器，解码器依据句子编码正确输出翻译句子的内容包括句子的结束 “&lt;eos&gt;” ，\n",
    "而解码器的初始时间步输入是表示句子开始的符号 “&lt;bos&gt;”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **编码器**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编码器的作用是将不定长的输入序列变成一个定长的背景向量$c$，并在该背景中编码输入序列信息。常用的编码器是循环神经网络或transfomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们把单个神经元的作用写在这里"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "h_t = f(x_t, h_{t-1}) \\hspace{3em} \\text{非LSTM} \\\\\n",
    "h_t = f(x_t, h_{t-1}, c_{t-1}) \\hspace{3em}  \\text{LSTM}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么编码器的作用就是："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$c = q(h_1,h_2,.....,h_T)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的$q$我们可以选择是最后一个隐层也可以是平均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **解码器**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解码器在时间步t的输出依赖于之前的输出以及编码器的输入，解码器得到的结果其实是"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(y_{t^*}|y_1, .....,y_{t^*-1},c)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为此，其实解码器当前时间步的隐层状态的计算如下所示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$s^* = g(y_{t^*-1}, c, s_{t^*-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **训练**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由最大似然估计，我们需要最大化的概率是"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "P(y_1, \\ldots, y_{T'} \\mid x_1, \\ldots, x_T)\n",
    "&= \\prod_{t'=1}^{T'} P(y_{t'} \\mid y_1, \\ldots, y_{t'-1}, x_1, \\ldots, x_T)\\\\\n",
    "&= \\prod_{t'=1}^{T'} P(y_{t'} \\mid y_1, \\ldots, y_{t'-1}, \\boldsymbol{c}),\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数极大似然"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$-\\log P(y_1, \\ldots, y_{T'} \\mid x_1, \\ldots, x_T) = -\\sum_{t'=1}^{T'} \\log P(y_{t'} \\mid y_1, \\ldots, y_{t'-1}, \\boldsymbol{c})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Beam Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么如何使用Seq2Seq来预测具体的每个句子呢？我们假设输出文本的词典为$\\mathcal Y$,输出序列的最大长度为$T'$,那么最后的输出序列总共有\n",
    "$|\\mathcal Y|^{T'}$种"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **贪婪搜索**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于每一个时间步$t'$,我们从所有词种找到概率最大的词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y _ { t ^ { \\prime } } = \\underset { y \\in \\mathcal { Y } } { \\operatorname { argmax } } P \\left( y | y _ { 1 } , \\ldots , y _ { t ^ { \\prime } - 1 } , c \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦输出了&lt;eos&gt;我们就认为结束了搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"200\" src=\"../image/10.10_s2s_prob1.svg\"/>\n",
    "</div>\n",
    "<div align=center>图10.9 在每个时间步，贪婪搜索选取条件概率最大的词</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上图为例，当时间步2选择了B后，时间步3的条件最大概率是0.4，最终句子的概率为$0.5 \\times 0.4 \\times 0.4 \\times 0.6 = 0.048$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"200\" src=\"../image/10.10_s2s_prob2.svg\"/>\n",
    "</div>\n",
    "<div align=center>图10.10 在时间步2选取条件概率第二大的词“C”</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再如上图,当第二步选择了C后，后续的概率如图，句子概率为$0.5 \\times 0.3 \\times 0.6 \\times 0.6 = 0.054$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，贪婪搜索不是最佳的句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **beam Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "束搜索（beam search）是对贪婪搜索的一个改进算法。它有一个束宽（beam size）超参数。我们将它设为$k$。在时间步1时，选取当前时间步条件概率最大的$k$个词，分别组成$k$个候选输出序列的首词。在之后的每个时间步，基于上个时间步的$k$个候选输出序列，从$k\\left|\\mathcal{Y}\\right|$个可能的输出序列中选取条件概率最大的$k$个，作为该时间步的候选输出序列。最终，我们从各个时间步的候选输出序列中筛选出包含特殊符号“&lt;eos&gt;”的序列，并将它们中所有特殊符号“&lt;eos&gt;”后面的子序列舍弃，得到最终候选输出序列的集合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"500\" src=\"../image/10.10_beam_search.svg\"/>\n",
    "</div>\n",
    "<div align=center>图10.11 束搜索的过程。束宽为2，输出序列最大长度为3。候选输出序列有A、C、AB、CE、ABD和CED</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在最终候选输出序列的集合中，我们取以下分数最高的序列作为输出序列：\n",
    "\n",
    "$$ \\frac{1}{L^\\alpha} \\log P(y_1, \\ldots, y_{L}) = \\frac{1}{L^\\alpha} \\sum_{t'=1}^L \\log P(y_{t'} \\mid y_1, \\ldots, y_{t'-1}, \\boldsymbol{c}),$$\n",
    "\n",
    "其中$L$为最终候选序列长度，$\\alpha$一般可选为0.75。分母上的$L^\\alpha$是为了惩罚较长序列在以上分数中较多的对数相加项。分析可知，束搜索的计算开销为$\\mathcal{O}(k\\left|\\mathcal{Y}\\right|T')$。这介于贪婪搜索和穷举搜索的计算开销之间。此外，贪婪搜索可看作是束宽为1的束搜索。束搜索通过灵活的束宽$k$来权衡计算开销和搜索质量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **attention机制**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解码器不同位置词语的输出其实需要用到的信息是不一样的，原句子的词语对本时间步的输出影响有所不同。让我们来看下属公式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$s^* = g(y_{t^*-1}, c, s_{t^*-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个时间步的c可以不同，从解码器的输出不同变化得到，那么这个公式就变成了："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$s' = g(y_{t'-1}, c_{t'-1}, s_{t'-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **背景变量的计算**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们把$c_{t'-1}$称为背景变量，那么如何计算背景变量呢?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"500\" src=\"../image/10.11_attention.svg\"/>\n",
    "</div>\n",
    "<div align=center>图10.12 编码器—解码器上的注意力机制</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给编码器的隐藏状态的每个输出一个权重，那么"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$c_{t'} = \\sum_{t=1}^{T}a_{t't}{h_t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么问题就转换成为了权重$a_{t't}$的计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a_{t't} = \\frac {exp(e_{t't})}{\\sum_{k=1}^Texp(e_{t'k})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用softmax的方式计算权重，那么$e_{t't}$怎么计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$e_{t't} = a(s_{t'-1}, h_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的计算有很多种方式，最简单的计算方式是计算$s_{t'-1}$和$h_t$的内积，当然还有别的方式，最早的方式设定了三个可训练张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a(\\boldsymbol{s}, \\boldsymbol{h}) = \\boldsymbol{v}^\\top \\tanh(\\boldsymbol{W}_s \\boldsymbol{s} + \\boldsymbol{W}_h \\boldsymbol{h}),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **矢量化计算**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们假设$s_{t'-1}$为$Q \\in \\mathbb R^{(1 \\times h)}$, 令编码器的输出矩阵$H$为$H = K = V \\in \\mathbb R^{(T \\times h)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么矢量化计算为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$softmax(QK^T)V$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以此得到的解码器计算为(以GPU为例)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{r}_{t'} &= \\sigma(\\boldsymbol{W}_{yr} \\boldsymbol{y}_{t'-1} + \\boldsymbol{W}_{sr} \\boldsymbol{s}_{t' - 1} + \\boldsymbol{W}_{cr} \\boldsymbol{c}_{t'} + \\boldsymbol{b}_r),\\\\\n",
    "\\boldsymbol{z}_{t'} &= \\sigma(\\boldsymbol{W}_{yz} \\boldsymbol{y}_{t'-1} + \\boldsymbol{W}_{sz} \\boldsymbol{s}_{t' - 1} + \\boldsymbol{W}_{cz} \\boldsymbol{c}_{t'} + \\boldsymbol{b}_z),\\\\\n",
    "\\tilde{\\boldsymbol{s}}_{t'} &= \\text{tanh}(\\boldsymbol{W}_{ys} \\boldsymbol{y}_{t'-1} + \\boldsymbol{W}_{ss} (\\boldsymbol{s}_{t' - 1} \\odot \\boldsymbol{r}_{t'}) + \\boldsymbol{W}_{cs} \\boldsymbol{c}_{t'} + \\boldsymbol{b}_s),\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\boldsymbol{s}_{t'} = \\boldsymbol{z}_{t'} \\odot \\boldsymbol{s}_{t'-1}  + (1 - \\boldsymbol{z}_{t'}) \\odot \\tilde{\\boldsymbol{s}}_{t'},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **代码实现**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os, io\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import d2lzh as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD, BOS, EOS = '<pad>', '<bos>', '<eos>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **读取和预处理数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将一个序列中所有的词记录在all_tokens中以便之后构造词典，然后在该序列后面添加PAD直到序列\n",
    "# 长度变为max_seq_len，然后将序列保存在all_seqs中\n",
    "def process_one_seq(seq_tokens, all_tokens, all_seqs, max_seq_len):\n",
    "    all_tokens.extend(seq_tokens)\n",
    "    seq_tokens += [EOS] + [PAD] * (max_seq_len - len(seq_tokens) - 1)\n",
    "    all_seqs.append(seq_tokens)\n",
    "    \n",
    "def build_data(all_tokens, all_seqs):\n",
    "    vocab = Vocab.Vocab(collections.Counter(all_tokens), specials=[PAD, BOS, EOS])\n",
    "    indices = [[vocab.stoi[w] for w in seq] for seq in all_seqs] # 将词转变为indices\n",
    "    return vocab, torch.tensor(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用一个很小的法语转英语的数据集。我们需要为法语和英语分别创建词典，二者相互独立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(max_seq_len):\n",
    "    # 在这里我们把两种语言的max_seq_len设置为一样\n",
    "    in_tokens, out_tokens, in_seqs, out_seqs = [], [], [], []\n",
    "    with io.open('../datasets/fr-en-small.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        in_seq, out_seq = line.rstrip().split('\\t')\n",
    "        in_seq_tokens, out_seq_tokens = in_seq.split(' '), out_seq.split(' ')\n",
    "        if max(len(in_seq_tokens), len(out_seq_tokens)) > max_seq_len - 1:\n",
    "            continue # 如果加上eos后长度比max_seq_len要大那么就要放弃本条数据\n",
    "        process_one_seq(in_seq_tokens, in_tokens, in_seqs, max_seq_len)\n",
    "        process_one_seq(out_seq_tokens, out_tokens, out_seqs, max_seq_len)\n",
    "    in_vocab, in_data = build_data(in_tokens, in_seqs)\n",
    "    out_vocab, out_data = build_data(out_tokens, out_seqs)\n",
    "    return in_vocab, out_vocab, Data.TensorDataset(in_data, out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5,  4, 45,  3,  2,  0,  0]), tensor([ 8,  4, 27,  3,  2,  0,  0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = 7\n",
    "in_vocab, out_vocab, dataset = read_data(max_seq_len)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **含注意力机制的编码器和解码器**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **编码器**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们以GRU为例，pytorch中的GRU本身会输出最终时间步的多层隐藏状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, drop_prob=0, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=drop_prob)\n",
    "        \n",
    "    def forward(self, inputs, state):\n",
    "        embedding = self.embedding(inputs.long()).permute(1, 0, 2)\n",
    "        return self.rnn(embedding, state)\n",
    "    \n",
    "    def begin_state(self):\n",
    "        return None # 不输入state时，自动初始化为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 4, 16]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\n",
    "output, state = encoder(torch.zeros((4, 7)), encoder.begin_state())\n",
    "output.shape, state.shape # GRU的state是h, 而LSTM的是一个元组(h, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **attention_model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用较为传统的attention方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将输入连接后通过含单隐层的多层感知机交换。其中隐藏层数输入事解码器单时间上的隐藏状态和编码器在时间步上隐藏状态的**一一连接**, 输出为1，同时向量$V$的长度是一个超参数attention_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a(\\boldsymbol{s}, \\boldsymbol{h}) = \\boldsymbol{v}^\\top \\tanh(\\boldsymbol{W}_s \\boldsymbol{s} + \\boldsymbol{W}_h \\boldsymbol{h}),$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_model(input_size, attention_size):\n",
    "    # (m, seq_len, input_size) -> (m, seq_len, 1)\n",
    "    model = nn.Sequential(nn.Linear(input_size, attention_size, bias=False),\n",
    "                          nn.Tanh(),\n",
    "                          nn.Linear(attention_size, 1, bias=False))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编码器和解码器的隐藏单元数要相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_forward(model, enc_states, dec_state):\n",
    "    \"\"\"\n",
    "    enc_states:(time_step, batch_size, hidden_states)\n",
    "    dec_state:(batch_size, hidden_state)\n",
    "    \"\"\"\n",
    "    # 扩展dec_state\n",
    "    dec_states = dec_state.unsqueeze(0).expand_as(enc_states)\n",
    "    enc_and_dec_states = torch.cat((enc_states, dec_states), dim=2)\n",
    "    e = model(enc_and_dec_states)\n",
    "    alpha = F.softmax(e, dim=0)\n",
    "    return (alpha * enc_states).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len, batch_size, num_hiddens = 10, 4, 8\n",
    "model = attention_model(2*num_hiddens, 10) \n",
    "enc_states = torch.zeros((seq_len, batch_size, num_hiddens))\n",
    "dec_state = torch.zeros((batch_size, num_hiddens))\n",
    "attention_forward(model, enc_states, dec_state).shape # torch.Size([4, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **解码器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, attention_size, drop_prob=0):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.attention = attention_model(2*num_hiddens, attention_size)\n",
    "        # GRU的输入包含attention输出的c和实际输入，实际尺寸是2*embed_size\n",
    "        self.rnn = nn.GRU(2*embed_size, num_hiddens, num_layers, dropout=drop_prob)\n",
    "        self.out = nn.Linear(num_hiddens, vocab_size)\n",
    "        \n",
    "    def forward(self, cur_input, state, enc_states):\n",
    "        \"\"\"\n",
    "        cur_input:(batch, )\n",
    "        state:(num_layer, batch, num_hiddens)\n",
    "        \"\"\"\n",
    "        # 取state的最后一层计算第一步的attention参数\n",
    "        c = attention_forward(self.attention, enc_states, state[-1])\n",
    "        # 将嵌入后的输入和背景向量相连接\n",
    "        input_and_c = torch.cat((self.embedding(cur_input), c), dim=1) # (batch, 2*embed_size)\n",
    "        # 为输入和背景向量增加一个时间步维度，时间步个数为1，就是一个时间步为1的GRU\n",
    "        output, state = self.rnn(input_and_c.unsqueeze(0), state)\n",
    "        # 移除时间步维度，输出形状(批量大小, 输出词典大小)\n",
    "        output = self.out(output).squeeze(dim=0)\n",
    "        return output, state\n",
    "    \n",
    "    def begin_state(self, enc_state):\n",
    "        return enc_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **损失计算过程**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先实现`batch_loss`函数计算一个小批量的损失。解码器在最初时间步的输入是特殊字符`BOS`。之后，解码器在某时间步的输入为样本输出序列在上一时间步的词，即强制教学。此外，同word2vec中的实现一样，我们在这里也使用掩码变量避免填充项对损失函数计算的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_loss(encoder, decoder, X, Y, loss):\n",
    "    batch_size = X.shape[0]\n",
    "    enc_state = encoder.begin_state() # 将encoder的初始状态设置为0\n",
    "    # 计算encoder\n",
    "    enc_outputs, enc_state = encoder(X, enc_state)\n",
    "    # 初始化解码器的隐藏状态\n",
    "    dec_state  = decoder.begin_state(enc_state)\n",
    "    # 解码器初始时间的输入是BOS\n",
    "    dec_input = torch.tensor([out_vocab.stoi[BOS]] * batch_size)\n",
    "    # 掩码变量需要用来忽略标签为填充项的损失\n",
    "    mask, num_not_pad_tokens = torch.ones(batch_size,), 0\n",
    "    l = torch.tensor([0.0])\n",
    "    for y in Y.permute(1, 0): # Y(batch, seq_len)\n",
    "        dec_output, dec_state = decoder(dec_input, dec_state, enc_outputs)\n",
    "        l = l + (mask * loss(dec_output, y)).sum()\n",
    "        dec_input = y # 使用强制教学，即真实的值作为数据到下一步时间步的输入\n",
    "        num_not_pad_tokens += mask.sum().item() # 计算当前time_step的非pad元素个数并加入\n",
    "        mask = mask * (y != out_vocab.stoi[PAD]).float() # 将PAD对应位置的掩码设置为0\n",
    "    return l / num_not_pad_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, dataset, lr, batch_size, num_epochs):\n",
    "    enc_optimizer = torch.optim.Adam(encoder.parameters(), lr=lr)\n",
    "    dec_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss(reduction='none')\n",
    "    data_iter = Data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum = 0.0\n",
    "        for X, Y in data_iter:\n",
    "            enc_optimizer.zero_grad()\n",
    "            dec_optimizer.zero_grad()\n",
    "            l = batch_loss(encoder, decoder, X, Y, loss)\n",
    "            l.backward()\n",
    "            enc_optimizer.step()\n",
    "            dec_optimizer.step()\n",
    "            l_sum += l.item()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(\"epoch %d, loss %.3f\" % (epoch + 1, l_sum / len(data_iter))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss 0.403\n",
      "epoch 20, loss 0.185\n",
      "epoch 30, loss 0.087\n",
      "epoch 40, loss 0.060\n",
      "epoch 50, loss 0.039\n"
     ]
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers = 64, 64, 2\n",
    "attention_size, drop_prob, lr, batch_size, num_epochs = 10, 0.5, 0.01, 2, 50\n",
    "encoder = Encoder(len(in_vocab), embed_size, num_hiddens, num_layers,\n",
    "                  drop_prob)\n",
    "decoder = Decoder(len(out_vocab), embed_size, num_hiddens, num_layers,\n",
    "                  attention_size, drop_prob)\n",
    "train(encoder, decoder, dataset, lr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(encoder, decoder, input_seq, max_seq_len):\n",
    "    in_tokens = input_seq.split(' ')\n",
    "    in_tokens += [EOS] + [PAD] * (max_seq_len - len(in_tokens) - 1)\n",
    "    enc_input = torch.tensor([[in_vocab.stoi[tk] for tk in in_tokens]]) # batch=1\n",
    "    enc_state = encoder.begin_state()\n",
    "    enc_output, enc_state = encoder(enc_input, enc_state)\n",
    "    dec_input = torch.tensor([out_vocab.stoi[BOS]])\n",
    "    dec_state = decoder.begin_state(enc_state)\n",
    "    output_tokens = []\n",
    "    for _ in range(max_seq_len):\n",
    "        dec_output, dec_state = decoder(dec_input, dec_state, enc_output)\n",
    "        pred = dec_output.argmax(dim=1)\n",
    "        pred_token = out_vocab.itos[int(pred.item())]\n",
    "        if pred_token == EOS:  # 当任一时间步搜索出EOS时，输出序列即完成\n",
    "            break\n",
    "        else:\n",
    "            output_tokens.append(pred_token)\n",
    "            dec_input = pred\n",
    "    return output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they', 'are', 'watching', '.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = 'ils regardent .'\n",
    "translate(encoder, decoder, input_seq, max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们通常使用BLEU来计算翻译的准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU在nltk包有实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = ['I', 'love', 'apple', 'and', 'orange']\n",
    "pred_sts = [['I', 'love', 'banana', 'and', 'orange'], ['I', 'love', 'apple', 'and', 'orange']]\n",
    "sentence_bleu(pred_sts, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_tr12",
   "language": "python",
   "name": "tf2_tr12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
