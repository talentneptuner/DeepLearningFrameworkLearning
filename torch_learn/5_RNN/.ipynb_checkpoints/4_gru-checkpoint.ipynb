{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **门控循环单元GRU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度裁剪可以有效地解决神经网络梯度爆炸的问题，但是往往无法解决梯度衰减的问题。梯度衰减回导致后面的时间步难以捕捉和较前时间步的联系    \n",
    "    \n",
    "**门控神经单元GRU**是为了更好的捕捉序列中时间步距离较大时的依赖关系，通过学习的门在控制信息的流动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GRU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **重置门和更新门**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"500\" src=\"../image/6.7_gru_1.svg\"/>\n",
    "</div>\n",
    "<div align=center>图6.4 门控循环单元中重置门和更新门的计算</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU引入了重置门和更新门两个概念，修改了循环神经网络内部的计算方式      \n",
    "门控神经网络的重置门和更新门的输入都是上一步的隐藏状态$\\boldsymbol H_{t-1}$和当前时间步的输入$\\boldsymbol X_t$,而输出由激活函数为sigmoid的全连接层得到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设隐藏单元的个数为$h$，给定时间步$t$的小批量输入为$X_t \\in \\mathbb R^{n \\times d}$($n$是样本数, $d$是向量长度); 上一个时间步的隐藏状态为\n",
    "$H_{t-1} \\in \\mathbb R^{n \\times h}$。       \n",
    "那么重置门的输出$R_t \\in \\mathbb R^{n \\times h}$和更新门的输出为$Z_t \\in \\mathbb R^{n \\times h}$计算过程为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "\\boldsymbol R_t = \\sigma(X_tW_{xr} + H_{t-1}W_{hr} + b_r)\\\\\n",
    "\\boldsymbol Z_t = \\sigma(X_tW_{xz} + H_{t-1}W_{hz} + b_z)\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中$W_{xr}, W_{xz} \\in \\mathbb R^{d \\times h}$，而$W_{hr}, W_{hz} \\in \\mathbb R^{h \\times h}$,重置门和更新门的每一个元素的值域都是$[0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **候选隐藏状态的计算**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"500\" src=\"../image/6.7_gru_2.svg\"/>\n",
    "</div>\n",
    "<div align=center>图6.5 门控循环单元中候选隐藏状态的计算</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将上一时间步的隐藏状态和重置门做元素乘法，如果重置门接近于0那么就是丢弃当前元素，如果重置门接近于1，那么就是保留当前元素\n",
    "- 上一步计算的结果和本时间步的输入连接，再通过激活函数为tanh的全连接层输出候选隐藏妆台"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间步$t$的候选隐藏状态$\\tilde H_t \\in \\mathbb R^{n \\times h}$的计算过程为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\tilde H_t = tanh(X_tW_{xh} + (R_t \\odot H_{t-1})W_{hh} + b_h)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重置门控制了上一步的隐藏状态以何种形式流入当前的的候选隐藏状态，**重置门用来丢弃和预测无关的信息**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **隐藏状态**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终隐藏状态的计算的输入为更新门的输出$Z_t$,上一步的隐藏状态$H_{t-1}$,候选隐藏状态$\\tilde H_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_t = Z_t \\odot H_{t-1} + (1 - Z_t)\\odot \\tilde H_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更新门可以控制隐藏状态应该如何被包含当前时间步输入信息的候选隐藏状态所更新。如果更新门的数值一直为1的话，那么当前输入就不会进入到输出的隐藏状态中，这可以被看作是较早的隐藏状态一直保存到当前步，能够有效的应对梯度衰减的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"500\" src=\"../image/6.7_gru_3.svg\"/>\n",
    "</div>\n",
    "<div align=center>图6.6 门控循环单元中隐藏状态的计算</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结下来就是：    \n",
    "- 重置门有利于捕捉时间序列的短期依赖关系\n",
    "- 更新门有助于捕捉时间序列的长期依赖关系  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../utils\") \n",
    "import d2lzh as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **从零实现GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use cuda\n"
     ]
    }
   ],
   "source": [
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n",
    "print('will use', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "def get_params():\n",
    "    # 输出层初始化\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)\n",
    "        return torch.nn.Parameter(ts, requires_grad=True)\n",
    "    # 更新门，重置门，隐藏状态计算参数\n",
    "    def _three():\n",
    "        return (_one((num_inputs, num_hiddens)), \n",
    "                _one((num_hiddens, num_hiddens)),\n",
    "                torch.nn.Parameter(torch.zeros(num_hiddens, device=device, dtype=torch.float32), requires_grad=True))\n",
    "    W_xz, W_hz, b_z = _three() # 更新门参数\n",
    "    W_xr, W_hr, b_r = _three() # 重置门参数\n",
    "    W_xh, W_hh, b_h = _three() # 候选隐藏状态参数\n",
    "    \n",
    "    # 输出层参数\n",
    "    W_hq = _one((num_hiddens, num_outputs))\n",
    "    b_q = torch.nn.Parameter(torch.zeros(vocab_size, device=device, dtype=torch.float32), requires_grad=True)\n",
    "    return nn.ParameterList([W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **定义模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gru_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算模型 inputs(num_steps, batch_size, vocab_size)\n",
    "def gru(inputs, state, params):\n",
    "    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, _ = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        Z = torch.sigmoid(torch.matmul(X, W_xz) + torch.matmul(H, W_hz) + b_z)\n",
    "        R = torch.sigmoid(torch.matmul(X, W_xr) + torch.matmul(H, W_hr) + b_r)\n",
    "        H_tilda = torch.tanh(torch.matmul(X, W_xh) + R * torch.matmul(H, W_hh) + b_h)\n",
    "        H = Z * H_tilda + (1 - Z) * X\n",
    "        Y = torch.matmul(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return outputs, (H, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2\n",
    "pred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bd11a7b87fe7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                           \u001b[0mchar_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           \u001b[0mclipping_theta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                           prefixes)\n\u001b[0m",
      "\u001b[1;32mC:\\D\\ProgramFile\\jupyter\\learning\\torch_learn\\dive_to_dp\\utils\\d2lzh.py\u001b[0m in \u001b[0;36mtrain_and_predict_rnn\u001b[1;34m(rnn, get_params, init_rnn_state, num_hiddens, vocab_size, device, corpus_indices, idx_to_char, char_to_idx, is_random_iter, num_epochs, num_steps, lr, clipping_theta, batch_size, pred_period, pred_len, prefixes)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_random_iter\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 如使用相邻采样，在epoch开始时初始化隐藏状态\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_rnn_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hiddens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[0ml_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m         \u001b[0mdata_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_iter_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "d2l.train_and_predict_rnn(gru, get_params, init_gru_state, num_hiddens,\n",
    "                          vocab_size, device, corpus_indices, idx_to_char,\n",
    "                          char_to_idx, False, num_epochs, num_steps, lr,\n",
    "                          clipping_theta, batch_size, pred_period, pred_len,\n",
    "                          prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_tr12",
   "language": "python",
   "name": "tf2_tr12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
