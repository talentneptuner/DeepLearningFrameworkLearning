{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AlexNet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"600\" src=\"../image/5.6_alexnet.png\"/>\n",
    "</div>\n",
    "<div align=center>AlexNet网络结构</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alex包括八层变换(5层卷积, 3层全连接):\n",
    "- 第一层卷积: (11, 11)\n",
    "- 第二层卷积: (5, 5)\n",
    "- 之后的卷积: (3, 3)\n",
    "\n",
    "\n",
    "AlexNet将激活函数换成了Relu函数     \n",
    "AlexNet使用了dropout     \n",
    "我们实现简化后的AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\D\\ProgramFile\\jupyter\\torch_learn\\dive_to_dp\\utils') \n",
    "import d2lzh as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **模型定义**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                                  # 添加padding为2((5-1)/2)使得输入输出高度一致\n",
    "                                  nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                                  nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        self.fc = nn.Sequential(nn.Linear(256*5*5, 4096),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(4096, 4096),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(4096, 10))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feature = self.conv(x)\n",
    "        output = self.fc(feature.view(x.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **数据读取**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None, root='../datasets/FashionMnisT'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    \n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=(224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** 训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, nums_epochs = 0.001, 5\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2lzh import evaluate_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1: loss 0.6118 train_acc 0.7673 test_acc 0.8590\n",
      "epoch2: loss 0.3350 train_acc 0.8762 test_acc 0.8858\n",
      "epoch3: loss 0.2853 train_acc 0.8932 test_acc 0.8959\n",
      "epoch4: loss 0.2574 train_acc 0.9045 test_acc 0.9008\n",
      "epoch5: loss 0.2361 train_acc 0.9108 test_acc 0.9087\n"
     ]
    }
   ],
   "source": [
    "net = net.to(device)\n",
    "for epoch in range(nums_epochs):\n",
    "    train_l_sum, train_acc_sum, n, batch_count = 0.0, 0.0, 0, 0\n",
    "    for X, y in train_iter:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        train_l_sum += l.cpu()\n",
    "        train_acc_sum += (y_hat.argmax(dim=1) == y).float().cpu().sum()\n",
    "        n += y.shape[0]\n",
    "        batch_count += 1\n",
    "    test_acc = evaluate_accuracy(test_iter, net)\n",
    "    print(f'epoch{epoch+1}: loss {train_l_sum/batch_count:.4f} train_acc {train_acc_sum / n:.4f} test_acc {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数数量显示工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 54, 54]          11,712\n",
      "              ReLU-2           [-1, 96, 54, 54]               0\n",
      "         MaxPool2d-3           [-1, 96, 26, 26]               0\n",
      "            Conv2d-4          [-1, 256, 26, 26]         614,656\n",
      "              ReLU-5          [-1, 256, 26, 26]               0\n",
      "         MaxPool2d-6          [-1, 256, 12, 12]               0\n",
      "            Conv2d-7          [-1, 384, 12, 12]         885,120\n",
      "              ReLU-8          [-1, 384, 12, 12]               0\n",
      "            Conv2d-9          [-1, 384, 12, 12]       1,327,488\n",
      "             ReLU-10          [-1, 384, 12, 12]               0\n",
      "           Conv2d-11          [-1, 256, 12, 12]         884,992\n",
      "             ReLU-12          [-1, 256, 12, 12]               0\n",
      "        MaxPool2d-13            [-1, 256, 5, 5]               0\n",
      "           Linear-14                 [-1, 4096]      26,218,496\n",
      "             ReLU-15                 [-1, 4096]               0\n",
      "          Dropout-16                 [-1, 4096]               0\n",
      "           Linear-17                 [-1, 4096]      16,781,312\n",
      "             ReLU-18                 [-1, 4096]               0\n",
      "          Dropout-19                 [-1, 4096]               0\n",
      "           Linear-20                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 46,764,746\n",
      "Trainable params: 46,764,746\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 10.17\n",
      "Params size (MB): 178.39\n",
      "Estimated Total Size (MB): 188.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(net.cuda(), (1, 224, 224)) # 后面的是input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_tr12",
   "language": "python",
   "name": "tf2_tr12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
